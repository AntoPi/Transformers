{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpwwZch1QspO"
      },
      "outputs": [],
      "source": [
        "# example from : https://keras.io/examples/timeseries/timeseries_classification_transformer/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "idx = np.random.permutation(len(x_train))\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0"
      ],
      "metadata": {
        "id": "DdaGk5DPQtMC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdf94EmdQteP",
        "outputId": "c070e025-d8c1-49bc-fa11-383cdb2279df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.77637643],\n",
              "        [-0.5446458 ],\n",
              "        [-0.25085224],\n",
              "        ...,\n",
              "        [-0.38368884],\n",
              "        [-0.8734027 ],\n",
              "        [-1.3062779 ]],\n",
              "\n",
              "       [[ 1.5550525 ],\n",
              "        [ 1.6364609 ],\n",
              "        [ 1.572592  ],\n",
              "        ...,\n",
              "        [ 0.91430985],\n",
              "        [ 0.70308798],\n",
              "        [ 0.47441773]],\n",
              "\n",
              "       [[-0.01336894],\n",
              "        [ 0.61613126],\n",
              "        [ 1.1911388 ],\n",
              "        ...,\n",
              "        [-1.1921922 ],\n",
              "        [-1.7591011 ],\n",
              "        [-2.1756055 ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.3647958 ],\n",
              "        [-1.1167011 ],\n",
              "        [-0.73691709],\n",
              "        ...,\n",
              "        [-0.18345607],\n",
              "        [-0.89294897],\n",
              "        [-1.5165335 ]],\n",
              "\n",
              "       [[-0.04202453],\n",
              "        [-0.10614548],\n",
              "        [-0.21253018],\n",
              "        ...,\n",
              "        [ 2.3136228 ],\n",
              "        [ 2.0428254 ],\n",
              "        [ 1.6656433 ]],\n",
              "\n",
              "       [[-0.41345323],\n",
              "        [-0.75399997],\n",
              "        [-1.0740824 ],\n",
              "        ...,\n",
              "        [ 0.59454413],\n",
              "        [ 0.72572546],\n",
              "        [ 0.80443426]]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Attention and Normalization\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    return x + res"
      ],
      "metadata": {
        "id": "KtgwhKm0Qxj5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "4lZuJMIZQ3iF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=150,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwLVyubaQ6Pq",
        "outputId": "adaf2506-f237-4010-8cf1-486981de7d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 500, 1)]             0         []                            \n",
            "                                                                                                  \n",
            " multi_head_attention (Mult  (None, 500, 1)               7169      ['input_1[0][0]',             \n",
            " iHeadAttention)                                                     'input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 500, 1)               0         ['multi_head_attention[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization (Layer  (None, 500, 1)               2         ['dropout[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 500, 1)               0         ['layer_normalization[0][0]', \n",
            " Lambda)                                                             'input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 500, 4)               8         ['tf.__operators__.add[0][0]']\n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 500, 4)               0         ['conv1d[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 500, 1)               5         ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (None, 500, 1)               2         ['conv1d_1[0][0]']            \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TF  (None, 500, 1)               0         ['layer_normalization_1[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 500, 1)               7169      ['tf.__operators__.add_1[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'tf.__operators__.add_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 500, 1)               0         ['multi_head_attention_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 500, 1)               2         ['dropout_2[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TF  (None, 500, 1)               0         ['layer_normalization_2[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add_1[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 500, 4)               8         ['tf.__operators__.add_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 500, 4)               0         ['conv1d_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)           (None, 500, 1)               5         ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 500, 1)               2         ['conv1d_3[0][0]']            \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TF  (None, 500, 1)               0         ['layer_normalization_3[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add_2[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, 500, 1)               7169      ['tf.__operators__.add_3[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'tf.__operators__.add_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 500, 1)               0         ['multi_head_attention_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " layer_normalization_4 (Lay  (None, 500, 1)               2         ['dropout_4[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TF  (None, 500, 1)               0         ['layer_normalization_4[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add_3[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 500, 4)               8         ['tf.__operators__.add_4[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 500, 4)               0         ['conv1d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 500, 1)               5         ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_5 (Lay  (None, 500, 1)               2         ['conv1d_5[0][0]']            \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TF  (None, 500, 1)               0         ['layer_normalization_5[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add_4[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (Mu  (None, 500, 1)               7169      ['tf.__operators__.add_5[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'tf.__operators__.add_5[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 500, 1)               0         ['multi_head_attention_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " layer_normalization_6 (Lay  (None, 500, 1)               2         ['dropout_6[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TF  (None, 500, 1)               0         ['layer_normalization_6[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add_5[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)           (None, 500, 4)               8         ['tf.__operators__.add_6[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 500, 4)               0         ['conv1d_6[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)           (None, 500, 1)               5         ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_7 (Lay  (None, 500, 1)               2         ['conv1d_7[0][0]']            \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TF  (None, 500, 1)               0         ['layer_normalization_7[0][0]'\n",
            " OpLambda)                                                          , 'tf.__operators__.add_6[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 1)                    0         ['tf.__operators__.add_7[0][0]\n",
            " GlobalAveragePooling1D)                                            ']                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  256       ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 2)                    258       ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 29258 (114.29 KB)\n",
            "Trainable params: 29258 (114.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/150\n",
            "16/45 [=========>....................] - ETA: 18:09 - loss: 0.6932 - sparse_categorical_accuracy: 0.4941"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WCa2JVCCQ97x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}